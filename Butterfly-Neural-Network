{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5481697,"sourceType":"datasetVersion","datasetId":456014}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nimport random\nfrom keras.layers import Conv2D\nfrom keras.regularizers import l2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nimport os\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.applications.densenet import preprocess_input, decode_predictions, DenseNet121\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.applications.densenet import preprocess_input, decode_predictions, DenseNet121\nfrom tensorflow.keras.metrics import TopKCategoricalAccuracy","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"csv_file_path = '/kaggle/input/butterfly-images40-species/butterflies and moths.csv'\ndf = pd.read_csv(csv_file_path)\n\nprint(\"Original DataFrame:\")\nprint(df.head())\n\nsorted_df = df.sort_values(by='filepaths')\nsorted_df.reset_index(drop=True, inplace=True)\n\nprint(\"\\nSorted DataFrame:\")\nprint(sorted_df.head())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_images_from_directory(directory, top_n_classes=50):\n    image_data = []\n    image_labels = []\n    # Get all directories\n    all_dirs = [d for d in os.listdir(directory) if os.path.isdir(os.path.join(directory, d))]\n    # Sort directories and select the top_n_classes\n    selected_dirs = sorted(all_dirs)[:top_n_classes]\n\n    for dir_name in selected_dirs:\n        dir_path = os.path.join(directory, dir_name)\n        for file in os.listdir(dir_path):\n            if file.endswith(('jpg', 'jpeg', 'png')):\n                image_path = os.path.join(dir_path, file)\n                try:\n                    # Load and preprocess the image\n                    image = load_img(image_path, target_size=(224, 224))\n                    image = img_to_array(image)\n                    image = preprocess_input(image)\n\n                    # Append to lists\n                    image_data.append(image)\n                    image_labels.append(dir_name)\n                except Exception as e:\n                    print(f\"Error processing image {image_path}: {e}\")\n\n    return np.array(image_data), np.array(image_labels)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_directory = '/kaggle/input/butterfly-images40-species/train'\nx_train, y_train = load_images_from_directory(train_directory)\n\ntest_directory = '/kaggle/input/butterfly-images40-species/test'\nx_test, y_test = load_images_from_directory(test_directory)\n\nlabel_encoder = LabelEncoder()\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_test_encoded = label_encoder.transform(y_test)\n\ny_train_categorical = to_categorical(y_train_encoded, num_classes=50)\ny_test_categorical = to_categorical(y_test_encoded, num_classes=50)\n\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Input, Flatten\n\nrandom_row = sorted_df.sample(n=1).iloc[0]\nimage_path = random_row['filepaths']\nimage_path = os.path.join('/kaggle/input/butterfly-images40-species', image_path)\n\n\n# Step 3: Load the DenseNet121 model\nmodel = DenseNet121(weights='imagenet', include_top = False, input_shape = (224, 224, 3))\n\nfor layer in model.layers:\n    layer.trainable = False\n\nx = model.output\nx = Flatten()(x)\nx = Dense(1024, activation = 'relu')(x)\n\npredictions = Dense(50, activation = 'softmax',kernel_regularizer=l2(0.01))(x)\n\nmodel = Model(inputs = model.input, outputs = predictions)\n\nmodel.compile(optimizer= 'adam', loss = 'categorical_crossentropy', metrics=['accuracy', TopKCategoricalAccuracy(k=5)])\n\nmodel.fit(x_train, y_train_categorical, epochs=10, batch_size=500)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def decode_predictions(preds, top=5):\n    # Get top 'top' indices of the highest scores\n    top_indices = preds.argsort()[-top:][::-1]\n    result = [(label_encoder.classes_[i], preds[i]) for i in top_indices]\n    return result\n\ndef predict_and_show(image_path):\n    # Load the image\n    img = load_img(image_path, target_size=(224, 224))\n    img_array = img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0)\n    img_array = preprocess_input(img_array)\n\n    # Predict the probabilities\n    predictions = model.predict(img_array)\n    predictions = predictions.flatten()  # Flatten the predictions array if necessary\n\n    # Decode the predictions\n    decoded_predictions = decode_predictions(predictions, top=5)\n\n    # Show the image\n    plt.imshow(img)\n    plt.axis('off')\n    plt.show()\n\n    # Print the predictions\n    for label, score in decoded_predictions:\n        print(f\"{label}: {score:.2f}\")\n\ndef get_random_image_path(directory):\n    image_paths = []\n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            if file.endswith(('jpg', 'jpeg', 'png')):\n                image_paths.append(os.path.join(root, file))\n    if image_paths:\n        return random.choice(image_paths)  # Randomly select one image path\n    return None  # Return None if no image found\n\nvalid_directory = '/kaggle/input/butterfly-images40-species/valid'\n# Get one random image path from the test directory\nall_dirs = [d for d in os.listdir(valid_directory) if os.path.isdir(os.path.join(valid_directory, d))]\n# Sort them alphabetically and take the first 50\nsorted_dirs = sorted(all_dirs)[:50]\n\n# Now collect image paths from these directories\nimage_paths = []\nfor dir in sorted_dirs:\n    dir_path = os.path.join(valid_directory, dir)\n    for file in os.listdir(dir_path):\n        if file.endswith(('jpg', 'jpeg', 'png')):\n            image_paths.append(os.path.join(dir_path, file))\n\n# Choose a random image path from the collected paths\nimage_path = random.choice(image_paths) if image_paths else None\n\n# Call the prediction and display function on this single random image\nif image_path:\n    predict_and_show(image_path)\n    path_parts = image_path.split('/')\n    species_name = path_parts[-2]\n    print(\"Correct Species: \", species_name)\nelse:\n    print(\"No images found in the specified directory.\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##CONFUSION MATRIX\n\nlabel_names = []\ncounter = 0\n\nfor label in df['labels']:\n    if len(label_names) <= 50:\n        if label not in label_names:\n            label_names.append(label)\n\n\npredictions_prob = model.predict(x_test)\ny_pred = np.argmax(predictions_prob, axis=1)\ncmtl = confusion_matrix(y_test_encoded, y_pred)\n\n# Calculate per-class accuracy\nper_class_accuracytl = cmtl.diagonal() / cmtl.sum(axis=1)\n\n# Plot the confusion matrix as a heatmap\nplt.figure(figsize=(10, 8))\nsns.heatmap(cmtl, annot=True, cmap='Purples', fmt='g', xticklabels=label_names, yticklabels=label_names)\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.title('Confusion Matrix')\nplt.show()\n\nplt.figure(figsize=(4, 3))\nplt.scatter(labels_imgnum, per_class_accuracytl, color='blue')\nplt.title('Scatter Plot: Accuracy vs Number of Images per Species')\nplt.xlabel('Number of Images per Species')\nplt.ylabel('Accuracy')\nplt.grid(True)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]}]}