{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5481697,"sourceType":"datasetVersion","datasetId":456014}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nimport os\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.applications.densenet import preprocess_input, decode_predictions, DenseNet121\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.applications.densenet import preprocess_input, decode_predictions, DenseNet121","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-03T14:21:30.333305Z","iopub.execute_input":"2024-07-03T14:21:30.333710Z","iopub.status.idle":"2024-07-03T14:21:30.340677Z","shell.execute_reply.started":"2024-07-03T14:21:30.333681Z","shell.execute_reply":"2024-07-03T14:21:30.339393Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"csv_file_path = '/kaggle/input/butterfly-images40-species/butterflies and moths.csv'\ndf = pd.read_csv(csv_file_path)\n\nprint(\"Original DataFrame:\")\nprint(df.head())\n\nsorted_df = df.sort_values(by='filepaths')\nsorted_df.reset_index(drop=True, inplace=True)\n\nprint(\"\\nSorted DataFrame:\")\nprint(sorted_df.head())","metadata":{"execution":{"iopub.status.busy":"2024-07-03T14:12:45.051199Z","iopub.execute_input":"2024-07-03T14:12:45.052259Z","iopub.status.idle":"2024-07-03T14:12:45.107443Z","shell.execute_reply.started":"2024-07-03T14:12:45.052212Z","shell.execute_reply":"2024-07-03T14:12:45.106104Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Original DataFrame:\n   class id             filepaths  labels data set\n0         0  train/ADONIS/001.jpg  ADONIS    train\n1         0  train/ADONIS/002.jpg  ADONIS    train\n2         0  train/ADONIS/003.jpg  ADONIS    train\n3         0  train/ADONIS/004.jpg  ADONIS    train\n4         0  train/ADONIS/005.jpg  ADONIS    train\n\nSorted DataFrame:\n   class id          filepaths  labels data set\n0         0  test/ADONIS/1.jpg  ADONIS     test\n1         0  test/ADONIS/2.jpg  ADONIS     test\n2         0  test/ADONIS/3.jpg  ADONIS     test\n3         0  test/ADONIS/4.jpg  ADONIS     test\n4         0  test/ADONIS/5.jpg  ADONIS     test\n","output_type":"stream"}]},{"cell_type":"code","source":"random_row = sorted_df.sample(n=1).iloc[0]\nimage_path = random_row['filepaths']\nimage_path = os.path.join('/kaggle/input/butterfly-images40-species', image_path)\nprint(f\"Randomly selected image: {image_path}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-03T14:12:47.453301Z","iopub.execute_input":"2024-07-03T14:12:47.453752Z","iopub.status.idle":"2024-07-03T14:12:47.464573Z","shell.execute_reply.started":"2024-07-03T14:12:47.453717Z","shell.execute_reply":"2024-07-03T14:12:47.463326Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Randomly selected image: /kaggle/input/butterfly-images40-species/train/ELBOWED PIERROT/075.jpg\n","output_type":"stream"}]},{"cell_type":"code","source":"\"\"\"\ndef load_images_from_directory(directory):\n    image_data = []\n    image_labels = []\n    \n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            if file.endswith(('jpg', 'jpeg', 'png')):\n                image_path = os.path.join(root, file)\n                label = os.path.basename(root)\n                \n                try:\n                    \n                    image = load_img(image_path, target_size=(224, 224))\n                    image = img_to_array(image)\n                    image = preprocess_input(image)\n                    \n                    image_data.append(image)\n                    image_labels.append(label)\n                    \n                except Exception as e:\n                    print(f\"Error processing image {image_path}: {e}\")\n       \n    return np.array(image_data), np.array(image_labels)\n\ntrain_directory = \"kaggle/input/train\"\n\nx_train, y_train = load_images_from_directory(train_directory)\n\ntest_directory = \"kaggle/input/test\"\nx_test, y_test = load_images_from_directory(test_directory)\n\nlabel_encoder = LabelEncoder()\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_test_encoded = label_encoder.transform(y_test)\n\ny_train_categorical = to_categorical(y_train_encoded, num_classes=100)\ny_test_categorical = to_categorical(y_test_encoded, num_classes=100)\n\"\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-07-03T13:07:49.354843Z","iopub.execute_input":"2024-07-03T13:07:49.355849Z","iopub.status.idle":"2024-07-03T13:07:49.365830Z","shell.execute_reply.started":"2024-07-03T13:07:49.355810Z","shell.execute_reply":"2024-07-03T13:07:49.364552Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"def load_images_from_directory(directory):\n    image_data = []\n    image_labels = []\n    \n    for root, dirs, files in os.walk(directory):\n        for file in files:\n            if file.endswith(('jpg', 'jpeg', 'png')):\n                image_path = os.path.join(root, file)\n                label = os.path.basename(root)\n                try:\n                   # Load and preprocess the image\n                    image = load_img(image_path, target_size=(224, 224))\n                    image = img_to_array(image)\n                    image = preprocess_input(image)\n                  \n                   # Append to lists\n                    image_data.append(image)\n                    image_labels.append(label)\n                except Exception as e:\n                    print(f\"Error processing image {image_path}: {e}\")\n    return np.array(image_data), np.array(image_labels)","metadata":{"execution":{"iopub.status.busy":"2024-07-03T14:12:50.149089Z","iopub.execute_input":"2024-07-03T14:12:50.150422Z","iopub.status.idle":"2024-07-03T14:12:50.159304Z","shell.execute_reply.started":"2024-07-03T14:12:50.150379Z","shell.execute_reply":"2024-07-03T14:12:50.157868Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Load training data\ntrain_directory = '/kaggle/input/butterfly-images40-species/train'\nx_train, y_train = load_images_from_directory(train_directory)\n\n\n# Load testing data\ntest_directory = '/kaggle/input/butterfly-images40-species/test'\nx_test, y_test = load_images_from_directory(test_directory)\n\n\n# Encode labels\nlabel_encoder = LabelEncoder()\ny_train_encoded = label_encoder.fit_transform(y_train)\ny_test_encoded = label_encoder.transform(y_test)\n\ny_train_categorical = to_categorical(y_train_encoded, num_classes=100)\ny_test_categorical = to_categorical(y_test_encoded, num_classes=100)\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Input, Flatten\n\n\n# Step 3: Load the DenseNet121 model\nmodel = DenseNet121(weights='imagenet', include_top = False, input_shape = (224, 224, 3))\n\nfor layer in model.layers:\n    layer.trainable = False","metadata":{"execution":{"iopub.status.busy":"2024-07-03T14:15:38.970650Z","iopub.execute_input":"2024-07-03T14:15:38.971789Z","iopub.status.idle":"2024-07-03T14:16:10.504593Z","shell.execute_reply.started":"2024-07-03T14:15:38.971747Z","shell.execute_reply":"2024-07-03T14:16:10.503203Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"x = model.output\nx = Flatten()(x)\nx = Dense(1024, activation = 'relu')(x)\npredictions = Dense(100, activation = 'sigmoid')(x)\n\nmodel = Model(inputs = model.input, outputs = predictions)\n\nmodel.compile(optimizer= 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n\nmodel.fit(x_train, y_train_categorical, epochs=10, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2024-07-03T14:05:19.073968Z","iopub.execute_input":"2024-07-03T14:05:19.075303Z","iopub.status.idle":"2024-07-03T14:05:19.417417Z","shell.execute_reply.started":"2024-07-03T14:05:19.075248Z","shell.execute_reply":"2024-07-03T14:05:19.414844Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mx_test\u001b[49m)\n","\u001b[0;31mNameError\u001b[0m: name 'x_test' is not defined"],"ename":"NameError","evalue":"name 'x_test' is not defined","output_type":"error"}]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Input, Flatten\n\nrand_row = sorted_df.sample(n=1).iloc[0]\nimg_path = rand_row['filepaths']\nimg_path = os.path.join('kaggle/input', img_path)\n\nmodel = DenseNet121(weights = \"imagenet\", include_top=False, input_shape=(224,224,3))\n\nfor layer in model.layers:\n    layer.trainable=False\n    \nx = model.output\nx = Flatten()(x)\nx = Dense(1024, activation='relu')(x)\npredictions = Dense(100, activation=\"sigmoid\")(x)\n\nmodel = Model(inputs=model.input, outputs = predictions)\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel.fit(x_train, y_train_categorical, epochs=10, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2024-07-03T13:56:37.174085Z","iopub.execute_input":"2024-07-03T13:56:37.174517Z","iopub.status.idle":"2024-07-03T13:56:39.904816Z","shell.execute_reply.started":"2024-07-03T13:56:37.174487Z","shell.execute_reply":"2024-07-03T13:56:39.903093Z"},"trusted":true},"execution_count":89,"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[89], line 22\u001b[0m\n\u001b[1;32m     18\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(inputs\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39minput, outputs \u001b[38;5;241m=\u001b[39m predictions)\n\u001b[1;32m     20\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 22\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_categorical\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/models/functional.py:288\u001b[0m, in \u001b[0;36mFunctional._adjust_input_rank\u001b[0;34m(self, flat_inputs)\u001b[0m\n\u001b[1;32m    286\u001b[0m             adjusted\u001b[38;5;241m.\u001b[39mappend(ops\u001b[38;5;241m.\u001b[39mexpand_dims(x, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    287\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 288\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    289\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid input shape for input \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Expected shape \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mref_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but input has incompatible shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    291\u001b[0m     )\n\u001b[1;32m    292\u001b[0m \u001b[38;5;66;03m# Add back metadata.\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(flat_inputs)):\n","\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Functional.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(32,), dtype=float32). Expected shape (None, 224, 224, 3), but input has incompatible shape (32,)\u001b[0m\n\nArguments received by Functional.call():\n  • inputs=tf.Tensor(shape=(32,), dtype=float32)\n  • training=True\n  • mask=None"],"ename":"ValueError","evalue":"Exception encountered when calling Functional.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(32,), dtype=float32). Expected shape (None, 224, 224, 3), but input has incompatible shape (32,)\u001b[0m\n\nArguments received by Functional.call():\n  • inputs=tf.Tensor(shape=(32,), dtype=float32)\n  • training=True\n  • mask=None","output_type":"error"}]},{"cell_type":"code","source":"base_model = Sequential([\n    keras.Input(shape=(224,224,3)),\n    Conv2D(20, (5,5), activation='relu'),\n    MaxPooling2D(pool_size=(2, 2)),\n    Conv2D(40, (5,5), activation='relu'),\n    MaxPooling2D(pool_size=(2, 2)),\n    Flatten(),\n    Dropout(0.5),\n    Dense(640,activation='relu'),\n    Dropout(0.5),\n    Dense(1000,activation='relu'),\n    Dropout(0.5),\n    Dense(10,activation='softmax')\n])\n\nbase_model.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\nbase_model.fit(x_train,y_train,epochs=40,batch_size=10)\n\nscore = base_model.evaluate(x_test,y_test,batch_size=10)","metadata":{"execution":{"iopub.status.busy":"2024-07-03T14:21:34.972199Z","iopub.execute_input":"2024-07-03T14:21:34.972629Z","iopub.status.idle":"2024-07-03T14:21:35.017822Z","shell.execute_reply.started":"2024-07-03T14:21:34.972597Z","shell.execute_reply":"2024-07-03T14:21:35.016265Z"},"trusted":true},"execution_count":18,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m base_model \u001b[38;5;241m=\u001b[39m Sequential([\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mkeras\u001b[49m\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m224\u001b[39m,\u001b[38;5;241m224\u001b[39m,\u001b[38;5;241m3\u001b[39m)),\n\u001b[1;32m      3\u001b[0m     Conv2D(\u001b[38;5;241m20\u001b[39m, (\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m5\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m      4\u001b[0m     MaxPooling2D(pool_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)),\n\u001b[1;32m      5\u001b[0m     Conv2D(\u001b[38;5;241m40\u001b[39m, (\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m5\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m      6\u001b[0m     MaxPooling2D(pool_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)),\n\u001b[1;32m      7\u001b[0m     Flatten(),\n\u001b[1;32m      8\u001b[0m     Dropout(\u001b[38;5;241m0.5\u001b[39m),\n\u001b[1;32m      9\u001b[0m     Dense(\u001b[38;5;241m640\u001b[39m,activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     10\u001b[0m     Dropout(\u001b[38;5;241m0.5\u001b[39m),\n\u001b[1;32m     11\u001b[0m     Dense(\u001b[38;5;241m1000\u001b[39m,activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     12\u001b[0m     Dropout(\u001b[38;5;241m0.5\u001b[39m),\n\u001b[1;32m     13\u001b[0m     Dense(\u001b[38;5;241m10\u001b[39m,activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m ])\n\u001b[1;32m     16\u001b[0m base_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     17\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     18\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     19\u001b[0m base_model\u001b[38;5;241m.\u001b[39mfit(x_train,y_train,epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"],"ename":"NameError","evalue":"name 'keras' is not defined","output_type":"error"}]}]}